{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Data Science Jobs From Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Recently, there's been some media hubbub about how data science is one of the [best fields](https://www.glassdoor.com/List/Best-Jobs-in-America-LST_KQ0,20.htm) to get into. However, because of the [diversity](https://www.datacamp.com/community/tutorials/data-science-industry-infographic#gs.JoXjfNU) of roles in the field, there can be quite a bit of variety in job titles, responsibilities, and qualifications. For people looking to break into data science (like me), there are many factors to consider when job-hunting, but salary is definitely a big one. For this analysis, I built a webscraper to collect data from 627 data science jobs listed on [Indeed](www.indeed.com) in the Boston area. Then, I constructed a logistic regression model to determine which factors were good predictors of a high salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "### Webscraping\n",
    "\n",
    "Using the Python library Beautiful Soup, I scraped a unique job ID, job title, and company from 627 listings. However, the vast majority of job descriptions are not hosted on Indeed.com itself, but require you to navigate to companies' own job pages. To avoid having to scrape each unique company's page, I used Indeed's own search function to find the terms \"PhD\", \"start-up\", and \"Python\", the number of years of experience called for, and whether or not a job paid over $90,000 a year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib import urlopen\n",
    "import numpy as np\n",
    "\n",
    "# initialize lists to store job ID, title, and company\n",
    "job_ids = []\n",
    "titles = []\n",
    "companies = []\n",
    "\n",
    "# search for all jobs in Boston that pay a minimum of $20,000\n",
    "# since Indeed displays 10 jobs per page, I'll loop over each page of search results\n",
    "for i in np.arange(0,100,10):\n",
    "    URL = \"https://www.indeed.com/jobs?q=data+scientist+$20,000&l=Boston&start={}&pp\".format(str(i))\n",
    "    soup = BeautifulSoup(urlopen(URL).read(), 'html.parser')\n",
    "    results = soup.find_all('div', attrs={'data-tn-component': 'organicJob'})\n",
    "    for x in results:\n",
    "        # get unique job ID\n",
    "        job_id = x.find('h2', attrs={\"class\": \"jobtitle\"})['id']\n",
    "        job_ids.append(job_id)\n",
    "\n",
    "        # get company\n",
    "        company = x.find('span', attrs={\"itemprop\":\"name\"}).text.strip()\n",
    "        companies.append(company)\n",
    "\n",
    "        # get job title\n",
    "        title = x.find('a', attrs={'data-tn-element': \"jobTitle\"}).text.strip()\n",
    "        titles.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jl_9a7d42c7e9942208</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>DataRobot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jl_8fb80761e03f4f34</td>\n",
       "      <td>Computational Scientist</td>\n",
       "      <td>Seven Bridges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jl_df3319bfb55ad3cf</td>\n",
       "      <td>Principal Data Scientist (Boston)</td>\n",
       "      <td>QuantumBlack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jl_1ad7a363fd5d5e05</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>AIR Worldwide Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jl_04a882314da504d4</td>\n",
       "      <td>Mass Spectrometry Data Analyst, USA-Boston</td>\n",
       "      <td>Genedata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                job_id                                       title  \\\n",
       "0  jl_9a7d42c7e9942208                              Data Scientist   \n",
       "1  jl_8fb80761e03f4f34                     Computational Scientist   \n",
       "2  jl_df3319bfb55ad3cf           Principal Data Scientist (Boston)   \n",
       "3  jl_1ad7a363fd5d5e05                          Research Scientist   \n",
       "4  jl_04a882314da504d4  Mass Spectrometry Data Analyst, USA-Boston   \n",
       "\n",
       "                     company  \n",
       "0                  DataRobot  \n",
       "1              Seven Bridges  \n",
       "2               QuantumBlack  \n",
       "3  AIR Worldwide Corporation  \n",
       "4                   Genedata  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then, take all the lists and combine them into a dataframe\n",
    "import pandas as pd\n",
    "jobs = pd.DataFrame(columns = ['job_id','title','company'])\n",
    "jobs['job_id'] = job_ids\n",
    "jobs['title'] = titles\n",
    "jobs['company'] = companies\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the job titles, I'm also interested in whether those described as \"analysts\" pay less than those described as \"scientists\", so I'll make columns containing a 0 or 1 if the job contains either term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check titles for Scientist/Analyst descriptions\n",
    "scientists = []\n",
    "for i, row in jobs.iterrows():\n",
    "    title = unicode(row[1])\n",
    "    if \"Scientist\" in title:\n",
    "        scientists.append('1')\n",
    "    else:\n",
    "        scientists.append('0')\n",
    "\n",
    "analysts = []\n",
    "for i, row in jobs.iterrows():\n",
    "    title = unicode(row[1])\n",
    "    if \"Analyst\" in title:\n",
    "        analysts.append('1')\n",
    "    else:\n",
    "        analysts.append('0')\n",
    "\n",
    "# Add columns to jobs dataframe        \n",
    "jobs['analyst_title'] = analysts        \n",
    "jobs['scientist_title'] = scientists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>analyst_title</th>\n",
       "      <th>scientist_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jl_9a7d42c7e9942208</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>DataRobot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jl_8fb80761e03f4f34</td>\n",
       "      <td>Computational Scientist</td>\n",
       "      <td>Seven Bridges</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jl_df3319bfb55ad3cf</td>\n",
       "      <td>Principal Data Scientist (Boston)</td>\n",
       "      <td>QuantumBlack</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jl_1ad7a363fd5d5e05</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>AIR Worldwide Corporation</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jl_04a882314da504d4</td>\n",
       "      <td>Mass Spectrometry Data Analyst, USA-Boston</td>\n",
       "      <td>Genedata</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                job_id                                       title  \\\n",
       "0  jl_9a7d42c7e9942208                              Data Scientist   \n",
       "1  jl_8fb80761e03f4f34                     Computational Scientist   \n",
       "2  jl_df3319bfb55ad3cf           Principal Data Scientist (Boston)   \n",
       "3  jl_1ad7a363fd5d5e05                          Research Scientist   \n",
       "4  jl_04a882314da504d4  Mass Spectrometry Data Analyst, USA-Boston   \n",
       "\n",
       "                     company analyst_title scientist_title  \n",
       "0                  DataRobot             0               1  \n",
       "1              Seven Bridges             0               1  \n",
       "2               QuantumBlack             0               1  \n",
       "3  AIR Worldwide Corporation             0               1  \n",
       "4                   Genedata             1               0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataframe\n",
    "Using the url's generated from Indeed.com's Advanced Search function for my chosen keywords, I collected the job id's of those that were returned when I searched for \"PhD\", \"start-up\", \"Python\", and for 1,2,3, and 4+ years of experience. I saved these in separate dataframes containing job_id and a column indicating whether or not they had the given attribute. Then, I used an outer merge to combine the two dataframes on the 'job_id' column, and filled any NaN's in the new column with zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging the dataframe containing all jobs that called for a PhD\n",
    "jobs = pd.merge(jobs, phd_df, how = 'outer', on = 'job_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The completed dataframe looked something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Python</th>\n",
       "      <th>over_90k</th>\n",
       "      <th>has_phd</th>\n",
       "      <th>years</th>\n",
       "      <th>has_startup</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>scientist_title</th>\n",
       "      <th>analyst_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jl_f43cd8061406b3d7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Director of Data Science and Analysis</td>\n",
       "      <td>Fidelity Investments</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jl_90603c7f1f0af480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Analytics Engineer (Boston)</td>\n",
       "      <td>QuantumBlack</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jl_50022587c7a4a8d9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Data Scientist Intern: Pricing &amp; Profitability...</td>\n",
       "      <td>Wayfair</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jl_44da2bd2b0b7e145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>Amazon Corporate LLC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jl_f5945f64ec7013e3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MIT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  Python  over_90k  has_phd  years  has_startup  \\\n",
       "0  jl_f43cd8061406b3d7     1.0       1.0      0.0      0          0.0   \n",
       "1  jl_90603c7f1f0af480     1.0       1.0      0.0      0          0.0   \n",
       "2  jl_50022587c7a4a8d9     1.0       1.0      0.0      0          0.0   \n",
       "3  jl_44da2bd2b0b7e145     1.0       1.0      1.0      0          0.0   \n",
       "4  jl_f5945f64ec7013e3     1.0       1.0      0.0      0          0.0   \n",
       "\n",
       "                                               title               company  \\\n",
       "0              Director of Data Science and Analysis  Fidelity Investments   \n",
       "1                        Analytics Engineer (Boston)          QuantumBlack   \n",
       "2  Data Scientist Intern: Pricing & Profitability...               Wayfair   \n",
       "3                         Machine Learning Scientist  Amazon Corporate LLC   \n",
       "4                                     Data Scientist                   MIT   \n",
       "\n",
       "   scientist_title  analyst_title  \n",
       "0                0              0  \n",
       "1                0              0  \n",
       "2                1              0  \n",
       "3                1              0  \n",
       "4                1              0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model\n",
    "Since I collected salary data in a binary fashion (greater than $90,000 or not), I'll use a logistic regression to model the relationship between my predictors and salary. Although the year variable could be considered continuous, I'm going to use the number of years (1, 2, 3, or 4+) as categories, since job descriptions probably list just the minimum amount of experience they're asking for anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make dummy variables for each year\n",
    "# X is a matrix of my predictors and y contains the target\n",
    "import patsy\n",
    "X = patsy.dmatrix('~C(years) + C(Python) + C(has_phd) + C(has_startup) + C(scientist_title) + C(analyst_title)', jobs)\n",
    "y = jobs.over_90k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use a cross-validated gridsearch to find the best values of C, the inverse of the regularization parameter lambda, and the penalty. A high C-value means the model uses little regularization and a low C means high regularization. Next, I'll fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='f1_macro',\n",
       "       verbose=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use gridsearch to find best value of C and regularization type to optimize model\n",
    "from sklearn import linear_model, cross_validation, metrics, grid_search\n",
    "logreg = linear_model.LogisticRegression()\n",
    "C_vals = [0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0]\n",
    "penalties = ['l1','l2']\n",
    "\n",
    "gs = grid_search.GridSearchCV(logreg, {'penalty':penalties, 'C':C_vals}, verbose = True, cv = 5, scoring = 'f1_macro')\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'C': 2.5}\n"
     ]
    }
   ],
   "source": [
    "# Find out the optimized hyperparameter and penalty type for this model\n",
    "print gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit a model with these hyperparameters and get predictions\n",
    "gs_logreg = linear_model.LogisticRegression(C = 2.5, penalty = 'l2', solver = 'liblinear')\n",
    "gs_logreg.fit(X,y)\n",
    "predictions = gs_logreg.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "\n",
    "Now that I've fit the model, I'll make a confusion matrix to report the number of false positives and false negatives, as well as the number of jobs it categorized correctly. I'll also print its classification report, which will tell me the precision and recall of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Predicted < 90k  Predicted > 90k\n",
      "Listed < 90k              219               92\n",
      "Listed > 90k              106              210\n"
     ]
    }
   ],
   "source": [
    "# Make confusion matrix\n",
    "conmat= metrics.confusion_matrix(y, predictions, labels=gs_logreg.classes_)\n",
    "conmat= pd.DataFrame(conmat, columns=['Predicted < 90k', 'Predicted > 90k'], index=['Listed < 90k', 'Listed > 90k'])\n",
    "printconmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.70      0.69       311\n",
      "        1.0       0.70      0.66      0.68       316\n",
      "\n",
      "avg / total       0.68      0.68      0.68       627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print metrics.classification_report(y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix, I see that the model had 219 true positives and 210 true negatives, which means that it correctly predicted the salary for 429 out of the 627 jobs for an 68% accuracy rate. The precision value reflects the proportion of true positive predictions out of all positive predictions, and the recall reflects the proportion of true positives for a given class. Both have a value of 0.68, meaning the model isn't better at predicting whether a job pays less than $90,000 or more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model on new data\n",
    "Now that I've trained my model on the original 627 jobs I collected and evaluated it, I'll test its performance on new data. Following the same webscraping procedure, I created a new test dataset containing information on 350 new jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import dataframe of new jobs and make matrices\n",
    "testjobs = pd.read_csv('/Users/teresaborcuch/Desktop/test_jobs_clean.csv')\n",
    "test_X = patsy.dmatrix('~C(years) + C(Python) + C(has_phd) + C(has_startup) + C(scientist_title) + C(analyst_title)', testjobs)\n",
    "test_y = testjobs.over_90k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions for the new values of X\n",
    "pred_testjobs = gs_logreg.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Predicted < 90k  Predicted > 90k\n",
      "Listed < 90k              157               78\n",
      "Listed > 90k                2              113\n"
     ]
    }
   ],
   "source": [
    "# Make confusion matrix for the test jobs\n",
    "conmat1= metrics.confusion_matrix(test_y, pred_testjobs, labels=gs_logreg.classes_)\n",
    "conmat1= pd.DataFrame(conmat1, columns=['Predicted < 90k', 'Predicted > 90k'], index=['Listed < 90k', 'Listed > 90k'])\n",
    "print conmat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.67      0.80       235\n",
      "        1.0       0.59      0.98      0.74       115\n",
      "\n",
      "avg / total       0.86      0.77      0.78       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on test set\n",
    "print metrics.classification_report(test_y, pred_testjobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performed quite well on the new data! It correctly categorized 270 of the 350 jobs for a 77% accuracy rate overall. However, the precision rate for jobs paying over 90k is much worse than the precision rate for jobs paying under 90k, which is reflected in the 78 false positives. These are cases where the model predicted a high salary, but the job actually paid less. The recall value is also less for jobs under 90k, meaning that the model is less accurate for the lower paying jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "### Which factor is the best predictor of salary?\n",
    "\n",
    "To determine which of the variables (keywords \"PhD\", \"Python\", or \"start-up\", years of experience, or having \"scientist\" vs \"analyst\" in the job title) had the greatest impact on salary prediction, we have to look at the coefficients of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C(has_startup)[T.1.0]</td>\n",
       "      <td>1.379817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C(Python)[T.1.0]</td>\n",
       "      <td>1.322992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C(years)[T.4]</td>\n",
       "      <td>0.951387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C(has_phd)[T.1.0]</td>\n",
       "      <td>0.777108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C(years)[T.3]</td>\n",
       "      <td>0.460874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C(years)[T.2]</td>\n",
       "      <td>0.003773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C(scientist_title)[T.1]</td>\n",
       "      <td>-0.174541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-0.244983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C(years)[T.1]</td>\n",
       "      <td>-0.712101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C(analyst_title)[T.1]</td>\n",
       "      <td>-0.797851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  variable  coefficient\n",
       "7    C(has_startup)[T.1.0]     1.379817\n",
       "5         C(Python)[T.1.0]     1.322992\n",
       "4            C(years)[T.4]     0.951387\n",
       "6        C(has_phd)[T.1.0]     0.777108\n",
       "3            C(years)[T.3]     0.460874\n",
       "2            C(years)[T.2]     0.003773\n",
       "8  C(scientist_title)[T.1]    -0.174541\n",
       "0                Intercept    -0.244983\n",
       "1            C(years)[T.1]    -0.712101\n",
       "9    C(analyst_title)[T.1]    -0.797851"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get coefficients\n",
    "var = ['Intercept',\n",
    "     'C(years)[T.1]',\n",
    "     'C(years)[T.2]',\n",
    "     'C(years)[T.3]',\n",
    "     'C(years)[T.4]',\n",
    "     'C(Python)[T.1.0]',\n",
    "     'C(has_phd)[T.1.0]',\n",
    "     'C(has_startup)[T.1.0]',\n",
    "     'C(scientist_title)[T.1]',\n",
    "     'C(analyst_title)[T.1]']\n",
    "coef = gs_logreg.coef_[0]\n",
    "coefs = []\n",
    "for i in range(0,10):\n",
    "    coefs.append(coef[i])\n",
    "model_summary = pd.DataFrame(columns = ['variable','coefficient'])\n",
    "model_summary['variable'] = var\n",
    "model_summary['coefficient'] = coefs\n",
    "model_summary = model_summary.sort_values('coefficient', ascending = False)\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these values, jobs that contain \"start-up\" or \"Python\" in their descriptions are more likely to pay over \\$90,000. We can also see that the more years of experience a job calls for, the more likely it is to pay well, as the 4 years category has a higher coefficient than the three, two, or one year categories. On the other hand, as predicted, jobs that use the title \"analyst\" are more likely to pay under $90,000 than jobs titled \"scientist.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing False Positives\n",
    "If I were to apply this model to my job search, I would run the risk of getting my hopes up that a given job paid over \\$90,000 a year and then being disappointed when it actually paid less. This happened about 40% of the time on the test data (78 false positives out of 191 total predicted positives). I might decide that it's preferable to have the model that underestimates salary so that I could be expect a lower amount, but then be pleasantly surprised when the actual salary was higher. To do this, I could tinker with the probability threshold the model used to determine whether it predicted over 90k. Here, I employed the default of 0.5, but to cut down the number of false positives, I could change it to 0.75. This would mean that the model would predict a salary of over $90,00 for a particular job only if was 75% sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "From this analysis, I've learned that if a particular job uses the term \"start-up\" in its description, it's more 1.3 times more likely to pay over $90,000 than if it doesn't. However, I have to be cautious about concluding that start-ups necessarily pay more. Since the webscraper only returned jobs for which each keyword was mentioned, I don't know the context. A job description explicitly stating that the company is \"past its start-up days\" would be considered in the same category as a company describing itself as \"a small 5-person start-up\". \n",
    "\n",
    "So if I were using this model in my job search, I'd be optimistic about any jobs mentioning \"start-up\" or \"Python\" and wary of analyst positions, but cautiously so, given the high false positive rate. :)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
